{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-10T03:47:32.062590100Z",
     "start_time": "2023-12-10T03:47:29.239335500Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from datasets import load_dataset\n",
    "from preprocess import preprocess_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# making sure that the model trains on the GPU and not on the CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T03:47:32.089735500Z",
     "start_time": "2023-12-10T03:47:32.087738700Z"
    }
   },
   "id": "13f0a380fd7b378"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "train_data = load_dataset('financial_phrasebank','sentences_allagree')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T03:47:32.734067600Z",
     "start_time": "2023-12-10T03:47:32.099721100Z"
    }
   },
   "id": "a8a50c2dde90f51c"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['Sentences'] = train_data['train']['sentence']\n",
    "df['Labels'] = train_data['train']['label']\n",
    "df = df.dropna()\n",
    "df = df.drop_duplicates()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T03:47:32.754125100Z",
     "start_time": "2023-12-10T03:47:32.744942800Z"
    }
   },
   "id": "cd2e2feb1ccb6802"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "       Sentences                                                            \\\n           count unique                                                top   \nLabels                                                                       \n0            303    303  Jan. 6 -- Ford is struggling in the face of sl...   \n1           1386   1386  According to Gran , the company has no plans t...   \n2            570    570  For the last quarter of 2010 , Componenta 's n...   \n\n             \n       freq  \nLabels       \n0         1  \n1         1  \n2         1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th colspan=\"4\" halign=\"left\">Sentences</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>count</th>\n      <th>unique</th>\n      <th>top</th>\n      <th>freq</th>\n    </tr>\n    <tr>\n      <th>Labels</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>303</td>\n      <td>303</td>\n      <td>Jan. 6 -- Ford is struggling in the face of sl...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1386</td>\n      <td>1386</td>\n      <td>According to Gran , the company has no plans t...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>570</td>\n      <td>570</td>\n      <td>For the last quarter of 2010 , Componenta 's n...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Labels').describe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T03:47:32.792433800Z",
     "start_time": "2023-12-10T03:47:32.759109800Z"
    }
   },
   "id": "48f347deb4bb0cf5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "UNDERSAMPLING THE CLASSES TO THE LENGTH OF THE SMALLEST CLASS"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b694b9166718a1b"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "909\n"
     ]
    }
   ],
   "source": [
    "p = df.groupby('Labels')\n",
    "p = p.apply(lambda x: x.sample(p.size().min()).reset_index(drop=True))\n",
    "p = p.reset_index(drop = True)\n",
    "df = p\n",
    "print(len(df))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T03:47:32.806372200Z",
     "start_time": "2023-12-10T03:47:32.789431500Z"
    }
   },
   "id": "5a5dd4b576b81f90"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "       Sentences                                                            \\\n           count unique                                                top   \nLabels                                                                       \n0            303    303  The situation of coated magazine printing pape...   \n1            303    303  Huhtamaki 's rigid plastic consumer goods oper...   \n2            303    303  Talentum expects that the net sales of its cor...   \n\n             \n       freq  \nLabels       \n0         1  \n1         1  \n2         1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th colspan=\"4\" halign=\"left\">Sentences</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>count</th>\n      <th>unique</th>\n      <th>top</th>\n      <th>freq</th>\n    </tr>\n    <tr>\n      <th>Labels</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>303</td>\n      <td>303</td>\n      <td>The situation of coated magazine printing pape...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>303</td>\n      <td>303</td>\n      <td>Huhtamaki 's rigid plastic consumer goods oper...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>303</td>\n      <td>303</td>\n      <td>Talentum expects that the net sales of its cor...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Labels').describe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T03:47:32.970967200Z",
     "start_time": "2023-12-10T03:47:32.826319Z"
    }
   },
   "id": "bcca93510bc3b25d"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "df['Sentences'] = df['Sentences'].apply(preprocess_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T03:47:34.797780400Z",
     "start_time": "2023-12-10T03:47:32.872202Z"
    }
   },
   "id": "8b309f3759ba12db"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T03:47:36.105214100Z",
     "start_time": "2023-12-10T03:47:34.805764300Z"
    }
   },
   "id": "40e2043a4fdddf2d"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def fitBERT(dataFrame):\n",
    "    max_length = 512  \n",
    "    batch_size = 16\n",
    "    num_epochs = 10\n",
    "    df = dataFrame\n",
    "    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    train_labels = torch.tensor(np.array(train_df['Labels']))\n",
    "    test_labels = torch.tensor(np.array(test_df['Labels']))\n",
    "    def tokenize_data(data):\n",
    "        tokenized = tokenizer.batch_encode_plus(\n",
    "            data,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return tokenized\n",
    "    train_tokenized = tokenize_data(train_df['Sentences'].tolist())\n",
    "    test_tokenized = tokenize_data(test_df['Sentences'].tolist())\n",
    "    \n",
    "    train_dataset = TensorDataset(train_tokenized['input_ids'], train_tokenized['attention_mask'], train_labels)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    test_dataset = TensorDataset(test_tokenized['input_ids'], test_tokenized['attention_mask'], test_labels)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        model.train()\n",
    "        running_train_loss = 0.0\n",
    "        correct_train_predictions = 0\n",
    "        total_train_predictions = 0\n",
    "        for step, batch in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch + 1} - Training\", unit=\"batch\")):\n",
    "            input_ids, attention_mask, labels = batch\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            labels = labels.to(device)\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels.unsqueeze(1))\n",
    "            loss = outputs.loss\n",
    "            running_train_loss += loss.item()\n",
    "    \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            _, predicted = torch.max(outputs.logits, 1)\n",
    "            total_train_predictions += labels.size(0)\n",
    "            correct_train_predictions += (predicted == labels).sum().item()\n",
    "        \n",
    "\n",
    "        train_epoch_loss = running_train_loss / len(train_loader)\n",
    "        train_epoch_accuracy = (correct_train_predictions / total_train_predictions) * 100\n",
    "        print(f\"Train Loss: {train_epoch_loss:.4f} - Train Accuracy: {train_epoch_accuracy:.2f}%\")\n",
    "    \n",
    "    \n",
    "        model.eval()\n",
    "        running_test_loss = 0.0\n",
    "        correct_test_predictions = 0\n",
    "        total_test_predictions = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for test_step, test_batch in enumerate(tqdm(test_loader, desc=f\"Epoch {epoch + 1} - Testing\", unit=\"batch\")):\n",
    "                test_input_ids, test_attention_mask, test_labels = test_batch\n",
    "                test_input_ids = test_input_ids.to(device)\n",
    "                test_attention_mask = test_attention_mask.to(device)\n",
    "                test_labels = test_labels.to(device)\n",
    "    \n",
    "                test_outputs = model(test_input_ids, attention_mask=test_attention_mask, labels=test_labels.unsqueeze(1))\n",
    "                test_loss = test_outputs.loss\n",
    "                running_test_loss += test_loss.item()\n",
    "    \n",
    "                _, test_predicted = torch.max(test_outputs.logits, 1)\n",
    "                total_test_predictions += test_labels.size(0)\n",
    "                correct_test_predictions += (test_predicted == test_labels).sum().item()\n",
    "                \n",
    "        # Calculate test accuracy and loss for the epoch\n",
    "        test_epoch_loss = running_test_loss / len(test_loader)\n",
    "        test_epoch_accuracy = (correct_test_predictions / total_test_predictions) * 100\n",
    "        print(f\"Test Loss: {test_epoch_loss:.4f} - Test Accuracy: {test_epoch_accuracy:.2f}%\")\n",
    "    \n",
    "    print(\"Training finished.\")\n",
    "    return model\n",
    "    \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T03:47:36.150009100Z",
     "start_time": "2023-12-10T03:47:36.119177300Z"
    }
   },
   "id": "8169dd0330799f4d"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training: 100%|██████████| 46/46 [00:20<00:00,  2.21batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0347 - Train Accuracy: 42.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Testing: 100%|██████████| 12/12 [00:01<00:00,  7.25batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.9113 - Test Accuracy: 50.55%\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Training: 100%|██████████| 46/46 [00:20<00:00,  2.30batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7894 - Train Accuracy: 61.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Testing: 100%|██████████| 12/12 [00:01<00:00,  7.18batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.7266 - Test Accuracy: 73.63%\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Training: 100%|██████████| 46/46 [00:20<00:00,  2.29batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5873 - Train Accuracy: 77.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Testing: 100%|██████████| 12/12 [00:01<00:00,  7.13batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.5682 - Test Accuracy: 80.22%\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Training: 100%|██████████| 46/46 [00:20<00:00,  2.29batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4232 - Train Accuracy: 85.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Testing: 100%|██████████| 12/12 [00:01<00:00,  7.13batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.4893 - Test Accuracy: 81.87%\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Training: 100%|██████████| 46/46 [00:20<00:00,  2.29batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2803 - Train Accuracy: 92.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Testing: 100%|██████████| 12/12 [00:01<00:00,  7.12batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.4050 - Test Accuracy: 85.71%\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Training: 100%|██████████| 46/46 [00:20<00:00,  2.29batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2034 - Train Accuracy: 93.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Testing: 100%|██████████| 12/12 [00:01<00:00,  7.11batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.3996 - Test Accuracy: 85.71%\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Training: 100%|██████████| 46/46 [00:20<00:00,  2.29batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1515 - Train Accuracy: 95.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Testing: 100%|██████████| 12/12 [00:01<00:00,  7.11batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.4107 - Test Accuracy: 85.71%\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Training: 100%|██████████| 46/46 [00:20<00:00,  2.28batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1156 - Train Accuracy: 96.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Testing: 100%|██████████| 12/12 [00:01<00:00,  7.08batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.4206 - Test Accuracy: 85.16%\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Training: 100%|██████████| 46/46 [00:20<00:00,  2.28batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0837 - Train Accuracy: 98.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Testing: 100%|██████████| 12/12 [00:01<00:00,  7.07batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.4653 - Test Accuracy: 84.62%\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Training: 100%|██████████| 46/46 [00:20<00:00,  2.28batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0863 - Train Accuracy: 97.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Testing: 100%|██████████| 12/12 [00:01<00:00,  7.07batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.5336 - Test Accuracy: 82.97%\n",
      "Training finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = fitBERT(df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T03:51:16.271951100Z",
     "start_time": "2023-12-10T03:47:36.127075700Z"
    }
   },
   "id": "fbebda1bf3e2b461"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T03:51:16.276970500Z",
     "start_time": "2023-12-10T03:51:16.270966700Z"
    }
   },
   "id": "53f940295d434e80"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T03:51:16.276970500Z",
     "start_time": "2023-12-10T03:51:16.270966700Z"
    }
   },
   "id": "42f6d84a74e3eea3"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T03:51:16.276970500Z",
     "start_time": "2023-12-10T03:51:16.270966700Z"
    }
   },
   "id": "6e54df7752d61391"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
