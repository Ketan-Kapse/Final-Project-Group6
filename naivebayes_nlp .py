# -*- coding: utf-8 -*-
"""Naivebayes_NLP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cqqCi6eiWnSxWlX91whz2gVrHRKHFbv4
"""

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, classification_report
from sklearn.feature_extraction.text import CountVectorizer
import pandas as pd

import nltk
import string
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer

import pandas as pd

def read_file_to_df(file_path):
    with open(file_path, 'r', encoding='latin-1') as file:
        lines = file.readlines()
    data = [line.strip().split('@') for line in lines if line.strip()]
    return pd.DataFrame(data, columns=['Sentence', 'Label'])

#combining the datasets
file_path_all_agree = 'Sentences_AllAgree.txt'
file_path_66_agree = 'Sentences_66Agree.txt'
file_path_75_agree = 'Sentences_75Agree.txt'
file_path_50_agree = 'Sentences_50Agree.txt'

df_all_agree = read_file_to_df(file_path_all_agree)
df_66_agree = read_file_to_df(file_path_66_agree)
df_75_agree = read_file_to_df(file_path_75_agree)
df_50_agree = read_file_to_df(file_path_50_agree)


combined_df = pd.concat([df_all_agree, df_66_agree, df_50_agree, df_75_agree], ignore_index=True)

print(combined_df.head())

nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')

lemmatizer = WordNetLemmatizer()

# preprocessing
def preprocess_text(text):
    text = text.lower()
    words = nltk.word_tokenize(text)
    words = [word for word in words if word not in stopwords.words('english')]
    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]
    return ' '.join(lemmatized_words)

# Preprocess the 'Sentence' column
combined_df['Processed_Sentence'] = combined_df['Sentence'].apply(preprocess_text)

vectorizer = CountVectorizer()
X = vectorizer.fit_transform(combined_df['Processed_Sentence'])
y = combined_df['Label']

combined_df.head()

nb_model = MultinomialNB()

# Initialize StratifiedKFold
from sklearn.model_selection import StratifiedKFold
skf = StratifiedKFold(n_splits=6)

accuracies = []

for train_index, test_index in skf.split(X, y):
    # Splitting the data into training and test sets for each fold
    X_train, X_test = X[train_index], X[test_index]
    y_train, y_test = y[train_index], y[test_index]

    # Training the model on the training set
    nb_model.fit(X_train, y_train)

    # Predicting on the test set
    y_pred = nb_model.predict(X_test)

    # Calculating accuracy
    accuracy = accuracy_score(y_test, y_pred)
    accuracies.append(accuracy)

# Calculating the average accuracy across all folds
average_accuracy = np.mean(accuracies)
print(f"Average Accuracy across all folds: {average_accuracy:.2f}")

#confusion matrix
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
import seaborn as sns
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d')
plt.title('Confusion Matrix')
plt.ylabel('Actual Label')
plt.xlabel('Predicted Label')
plt.show()

#ROC curve
from sklearn.metrics import roc_curve, auc
from sklearn.preprocessing import label_binarize
import numpy as np

y_test_binarized = label_binarize(y_test, classes=np.unique(y_test))
y_pred_proba = nb_model.predict_proba(X_test)
fpr, tpr, _ = roc_curve(y_test_binarized.ravel(), y_pred_proba.ravel())
roc_auc = auc(fpr, tpr)

# Plotting the ROC Curve
plt.figure()
lw = 2
plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic')
plt.legend(loc="lower right")
plt.show()